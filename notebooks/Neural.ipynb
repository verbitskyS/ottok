{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_churn = ['eqpdays','hnd_price','hnd_webcap','totmrc_Mean','asl_flag','crclscod','mou_Mean','mou_cvce_Mean',\n",
    " 'complete_Mean','comp_vce_Mean','mou_opkv_Mean','avg3mou','attempt_Mean','plcd_vce_Mean','peak_vce_Mean','opk_vce_Mean',\n",
    " 'mou_peav_Mean','mou_rvce_Mean','models','avg3qty','owylis_vce_Mean','area','avg6mou','recv_vce_Mean','ethnic','phones','uniqsubs',\n",
    " 'iwylis_vce_Mean','lor','avg6qty','unan_vce_Mean','ccrndmou_Mean','mouowylisv_Mean','custcare_Mean','inonemin_Mean',\n",
    " 'cc_mou_Mean','mouiwylisv_Mean','callwait_Mean','refurb_new','dualband','change_mou','threeway_Mean','avgmou', 'churn']\n",
    "\n",
    "most_important = ['eqpdays','hnd_price','hnd_webcap','totmrc_Mean','asl_flag','crclscod','mou_Mean','mou_cvce_Mean',\n",
    " 'complete_Mean','comp_vce_Mean','mou_opkv_Mean','avg3mou','attempt_Mean','plcd_vce_Mean','peak_vce_Mean','opk_vce_Mean',\n",
    " 'mou_peav_Mean','mou_rvce_Mean','models','avg3qty','owylis_vce_Mean','area','avg6mou','recv_vce_Mean','ethnic','phones','uniqsubs',\n",
    " 'iwylis_vce_Mean','lor','avg6qty','unan_vce_Mean','ccrndmou_Mean','mouowylisv_Mean','custcare_Mean','inonemin_Mean',\n",
    " 'cc_mou_Mean','mouiwylisv_Mean','callwait_Mean','refurb_new','dualband','change_mou','threeway_Mean','avgmou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46240 train examples\n",
      "11560 validation examples\n",
      "14450 test examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataframe = pd.read_csv('train.csv').drop(['Customer_ID'], axis=1)\n",
    "\n",
    "dataframe = dataframe.loc[:, most_important_churn]\n",
    "\n",
    "\n",
    "quantile_value = 0.999\n",
    "\n",
    "\n",
    "CATEGORICAL_COLUMNS = list(dataframe.select_dtypes(include='object'))\n",
    "NUMERIC_COLUMNS = list(dataframe.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "\n",
    "for column in NUMERIC_COLUMNS:\n",
    "    dataframe[column] = dataframe[column].fillna(dataframe[column].median())\n",
    "    q_high = dataframe[column].quantile(quantile_value)\n",
    "    q_low = dataframe[column].quantile(1 - quantile_value)\n",
    "    dataframe = dataframe[(dataframe[column] <= q_high) & (dataframe[column] >= q_low)]\n",
    "    dataframe[column]=((dataframe[column]-dataframe[column].min())/(dataframe[column].max()-dataframe[column].min()))\n",
    "    \n",
    "    #dataframe[column] = (dataframe[column] - dataframe[column].mean())/(dataframe[column].std())\n",
    "    \n",
    "for column in CATEGORICAL_COLUMNS:\n",
    "    dataframe[column] = dataframe[column].fillna(dataframe[column].describe().top)\n",
    "\n",
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  print(dataframe.head()) \n",
    "  labels = dataframe.pop('churn')\n",
    "  print(dataframe.head())  \n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "8840   0.185684  0.191475     0.339200  0.044693     0.000000     0.000000   \n",
      "50905  0.068035  0.131391     0.116784  0.016760     0.007958     0.008516   \n",
      "52275  0.041029  0.004064     0.097444  0.000000     0.000000     0.000000   \n",
      "43163  0.068730  0.056713     0.161912  0.005587     0.000000     0.000000   \n",
      "55801  0.154950  0.362998     0.323083  0.011173     0.038384     0.047925   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  forgntvl  ethnic  \\\n",
      "8840      0.000000          0.0        0.0    0.475765  ...       0.0       N   \n",
      "50905     0.009389          0.0        0.0    0.515049  ...       0.0       I   \n",
      "52275     0.000000          0.0        0.0    0.514686  ...       0.0       U   \n",
      "43163     0.000000          0.0        0.0    0.526103  ...       0.0       S   \n",
      "55801     0.052837          0.0        0.0    0.576129  ...       0.0       N   \n",
      "\n",
      "       kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd   eqpdays  churn  \n",
      "8840        U       U        U         U         U         Y  0.211806    1.0  \n",
      "50905       U       U        U         U         U         Y  0.004051    0.0  \n",
      "52275       U       U        U         U         U         Y  0.404514    1.0  \n",
      "43163       U       U        Y         U         U         Y  0.196759    1.0  \n",
      "55801       U       U        U         U         U         Y  0.133102    1.0  \n",
      "\n",
      "[5 rows x 99 columns]\n",
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "8840   0.185684  0.191475     0.339200  0.044693     0.000000     0.000000   \n",
      "50905  0.068035  0.131391     0.116784  0.016760     0.007958     0.008516   \n",
      "52275  0.041029  0.004064     0.097444  0.000000     0.000000     0.000000   \n",
      "43163  0.068730  0.056713     0.161912  0.005587     0.000000     0.000000   \n",
      "55801  0.154950  0.362998     0.323083  0.011173     0.038384     0.047925   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  dwllsize  \\\n",
      "8840      0.000000          0.0        0.0    0.475765  ...         A   \n",
      "50905     0.009389          0.0        0.0    0.515049  ...         A   \n",
      "52275     0.000000          0.0        0.0    0.514686  ...         A   \n",
      "43163     0.000000          0.0        0.0    0.526103  ...         A   \n",
      "55801     0.052837          0.0        0.0    0.576129  ...         A   \n",
      "\n",
      "       forgntvl  ethnic  kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  \\\n",
      "8840        0.0       N       U       U        U         U         U   \n",
      "50905       0.0       I       U       U        U         U         U   \n",
      "52275       0.0       U       U       U        U         U         U   \n",
      "43163       0.0       S       U       U        Y         U         U   \n",
      "55801       0.0       N       U       U        U         U         U   \n",
      "\n",
      "       creditcd   eqpdays  \n",
      "8840          Y  0.211806  \n",
      "50905         Y  0.004051  \n",
      "52275         Y  0.404514  \n",
      "43163         Y  0.196759  \n",
      "55801         Y  0.133102  \n",
      "\n",
      "[5 rows x 98 columns]\n",
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "43219  0.040762  0.007482     0.128252  0.005587     0.000000     0.000000   \n",
      "3081   0.041029  0.000000     0.097444  0.000000     0.000000     0.000000   \n",
      "38053  0.087438  0.091442     0.161912  0.000000     0.022000     0.023545   \n",
      "53578  0.048937  0.023830     0.113561  0.000000     0.001248     0.001737   \n",
      "37876  0.070180  0.142059     0.160566  0.000000     0.002496     0.002672   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  forgntvl  ethnic  \\\n",
      "43219     0.000000     0.000000   0.000000    0.525584  ...       0.0       Z   \n",
      "3081      0.000000     0.000000   0.000000    0.518838  ...       0.0       N   \n",
      "38053     0.025958     0.000000   0.000467    0.492475  ...       1.0       G   \n",
      "53578     0.000000     0.006661   0.000000    0.513856  ...       0.0       H   \n",
      "37876     0.002946     0.000000   0.000000    0.467981  ...       0.0       R   \n",
      "\n",
      "       kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd   eqpdays  churn  \n",
      "43219       U       Y        U         Y         Y         Y  0.190972    1.0  \n",
      "3081        U       U        U         U         U         Y  0.214699    0.0  \n",
      "38053       U       U        U         U         U         Y  0.227431    1.0  \n",
      "53578       U       U        U         U         U         Y  0.080440    0.0  \n",
      "37876       U       U        U         U         U         N  0.115162    0.0  \n",
      "\n",
      "[5 rows x 99 columns]\n",
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "43219  0.040762  0.007482     0.128252  0.005587     0.000000     0.000000   \n",
      "3081   0.041029  0.000000     0.097444  0.000000     0.000000     0.000000   \n",
      "38053  0.087438  0.091442     0.161912  0.000000     0.022000     0.023545   \n",
      "53578  0.048937  0.023830     0.113561  0.000000     0.001248     0.001737   \n",
      "37876  0.070180  0.142059     0.160566  0.000000     0.002496     0.002672   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  dwllsize  \\\n",
      "43219     0.000000     0.000000   0.000000    0.525584  ...         A   \n",
      "3081      0.000000     0.000000   0.000000    0.518838  ...         B   \n",
      "38053     0.025958     0.000000   0.000467    0.492475  ...         A   \n",
      "53578     0.000000     0.006661   0.000000    0.513856  ...         B   \n",
      "37876     0.002946     0.000000   0.000000    0.467981  ...         A   \n",
      "\n",
      "       forgntvl  ethnic  kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  \\\n",
      "43219       0.0       Z       U       Y        U         Y         Y   \n",
      "3081        0.0       N       U       U        U         U         U   \n",
      "38053       1.0       G       U       U        U         U         U   \n",
      "53578       0.0       H       U       U        U         U         U   \n",
      "37876       0.0       R       U       U        U         U         U   \n",
      "\n",
      "       creditcd   eqpdays  \n",
      "43219         Y  0.190972  \n",
      "3081          Y  0.214699  \n",
      "38053         Y  0.227431  \n",
      "53578         Y  0.080440  \n",
      "37876         N  0.115162  \n",
      "\n",
      "[5 rows x 98 columns]\n",
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "55245  0.105302  0.084930     0.113843  0.111732     0.049930     0.062342   \n",
      "11909  0.049203  0.022029     0.145795  0.000000     0.000780     0.001085   \n",
      "29664  0.047870  0.017596     0.145795  0.000000     0.000000     0.000000   \n",
      "42426  0.079305  0.149587     0.097476  0.000000     0.040256     0.050330   \n",
      "7882   0.085872  0.123355     0.194146  0.044693     0.016851     0.024041   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  forgntvl  ethnic  \\\n",
      "55245     0.068731     0.000000   0.000935    0.503944  ...       0.0       B   \n",
      "11909     0.000000     0.004163   0.002337    0.522937  ...       0.0       D   \n",
      "29664     0.000000     0.000000   0.000000    0.532901  ...       0.0       F   \n",
      "42426     0.054770     0.002498   0.000000    0.377530  ...       0.0       H   \n",
      "7882      0.026265     0.000833   0.000000    0.509341  ...       1.0       N   \n",
      "\n",
      "       kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd   eqpdays  churn  \n",
      "55245       U       U        U         U         U         Y  0.009259    1.0  \n",
      "11909       U       Y        U         U         U         Y  0.196181    1.0  \n",
      "29664       U       U        U         U         U         Y  0.210069    1.0  \n",
      "42426       U       U        U         U         U         Y  0.273727    1.0  \n",
      "7882        Y       U        U         Y         U         Y  0.142940    0.0  \n",
      "\n",
      "[5 rows x 99 columns]\n",
      "       rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
      "55245  0.105302  0.084930     0.113843  0.111732     0.049930     0.062342   \n",
      "11909  0.049203  0.022029     0.145795  0.000000     0.000780     0.001085   \n",
      "29664  0.047870  0.017596     0.145795  0.000000     0.000000     0.000000   \n",
      "42426  0.079305  0.149587     0.097476  0.000000     0.040256     0.050330   \n",
      "7882   0.085872  0.123355     0.194146  0.044693     0.016851     0.024041   \n",
      "\n",
      "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  dwllsize  \\\n",
      "55245     0.068731     0.000000   0.000935    0.503944  ...         A   \n",
      "11909     0.000000     0.004163   0.002337    0.522937  ...         A   \n",
      "29664     0.000000     0.000000   0.000000    0.532901  ...         A   \n",
      "42426     0.054770     0.002498   0.000000    0.377530  ...         A   \n",
      "7882      0.026265     0.000833   0.000000    0.509341  ...         A   \n",
      "\n",
      "       forgntvl  ethnic  kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  \\\n",
      "55245       0.0       B       U       U        U         U         U   \n",
      "11909       0.0       D       U       Y        U         U         U   \n",
      "29664       0.0       F       U       U        U         U         U   \n",
      "42426       0.0       H       U       U        U         U         U   \n",
      "7882        1.0       N       Y       U        U         Y         U   \n",
      "\n",
      "       creditcd   eqpdays  \n",
      "55245         Y  0.009259  \n",
      "11909         Y  0.196181  \n",
      "29664         Y  0.210069  \n",
      "42426         Y  0.273727  \n",
      "7882          Y  0.142940  \n",
      "\n",
      "[5 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 25 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eqpdays', 'hnd_price', 'totmrc_Mean', 'mou_Mean', 'mou_cvce_Mean', 'complete_Mean', 'comp_vce_Mean', 'mou_opkv_Mean', 'avg3mou', 'attempt_Mean', 'plcd_vce_Mean', 'peak_vce_Mean', 'opk_vce_Mean', 'mou_peav_Mean', 'mou_rvce_Mean', 'models', 'avg3qty', 'owylis_vce_Mean', 'avg6mou', 'recv_vce_Mean', 'phones', 'uniqsubs', 'iwylis_vce_Mean', 'lor', 'avg6qty', 'unan_vce_Mean', 'ccrndmou_Mean', 'mouowylisv_Mean', 'custcare_Mean', 'inonemin_Mean', 'cc_mou_Mean', 'mouiwylisv_Mean', 'callwait_Mean', 'change_mou', 'threeway_Mean', 'avgmou']\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "NUMERIC_COLUMNS = NUMERIC_COLUMNS[:-1]\n",
    "print(NUMERIC_COLUMNS)\n",
    "\n",
    "# numeric cols\n",
    "for header in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "\n",
    "\n",
    "#cat_col_tf = []\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    thal = feature_column.categorical_column_with_vocabulary_list(\n",
    "      col, dataframe[col].unique())\n",
    "    thal_one_hot = feature_column.indicator_column(thal)\n",
    "    feature_columns.append(thal_one_hot)\n",
    "    \n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = dataframe[col].unique()\n",
    "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(col, vocabulary)\n",
    "  embeding = feature_column.embedding_column(cat_c, dimension=50)\n",
    "  feature_columns.append(embeding)    \n",
    "\n",
    "# embedding cols\n",
    "#thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
    "#feature_columns.append(thal_embedding)\n",
    "\n",
    "# embedding cols\n",
    "#for header in CATEGORICAL_COLUMNS:\n",
    " #   thal_embedding = feature_column.embedding_column(header, dimension=8)\n",
    "  #  feature_columns.append(thal_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "70087  0.167404   0.128205       WCMB     0.282620        N       AA   \n",
      "61324  0.037903   0.435897       WCMB     0.154184        N       AA   \n",
      "28868  0.186987   0.128205       WCMB     0.050971        N       AA   \n",
      "17095  0.143399   0.358974       WCMB     0.411106        Y       CA   \n",
      "58562  0.396083   0.051282       WCMB     0.154133        N       AA   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "70087  0.144615       0.155431       0.138794       0.158854  ...   \n",
      "61324  0.052771       0.018081       0.016686       0.014757  ...   \n",
      "28868  0.021458       0.013843       0.026166       0.029948  ...   \n",
      "17095  0.174949       0.119047       0.058020       0.063368  ...   \n",
      "58562  0.105752       0.046919       0.139173       0.159288  ...   \n",
      "\n",
      "       inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  callwait_Mean  refurb_new  \\\n",
      "70087       0.025303     0.000000          0.00000       0.058140           N   \n",
      "61324       0.000000     0.000000          0.00000       0.000000           N   \n",
      "28868       0.011001     0.000000          0.00000       0.000000           N   \n",
      "17095       0.012101     0.055989          0.00000       0.000000           N   \n",
      "58562       0.117712     0.024249          0.03202       0.023256           N   \n",
      "\n",
      "       dualband  change_mou  threeway_Mean    avgmou  churn  \n",
      "70087         Y    0.427398       0.034483  0.150936    1.0  \n",
      "61324         T    0.569371       0.000000  0.075527    0.0  \n",
      "28868         Y    0.499954       0.000000  0.053048    1.0  \n",
      "17095         Y    0.544632       0.000000  0.298795    0.0  \n",
      "58562         N    0.456199       0.000000  0.107106    0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "70087  0.167404   0.128205       WCMB     0.282620        N       AA   \n",
      "61324  0.037903   0.435897       WCMB     0.154184        N       AA   \n",
      "28868  0.186987   0.128205       WCMB     0.050971        N       AA   \n",
      "17095  0.143399   0.358974       WCMB     0.411106        Y       CA   \n",
      "58562  0.396083   0.051282       WCMB     0.154133        N       AA   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "70087  0.144615       0.155431       0.138794       0.158854  ...   \n",
      "61324  0.052771       0.018081       0.016686       0.014757  ...   \n",
      "28868  0.021458       0.013843       0.026166       0.029948  ...   \n",
      "17095  0.174949       0.119047       0.058020       0.063368  ...   \n",
      "58562  0.105752       0.046919       0.139173       0.159288  ...   \n",
      "\n",
      "       custcare_Mean  inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  \\\n",
      "70087       0.000000       0.025303     0.000000          0.00000   \n",
      "61324       0.000000       0.000000     0.000000          0.00000   \n",
      "28868       0.000000       0.011001     0.000000          0.00000   \n",
      "17095       0.091743       0.012101     0.055989          0.00000   \n",
      "58562       0.091743       0.117712     0.024249          0.03202   \n",
      "\n",
      "       callwait_Mean  refurb_new  dualband  change_mou  threeway_Mean  \\\n",
      "70087       0.058140           N         Y    0.427398       0.034483   \n",
      "61324       0.000000           N         T    0.569371       0.000000   \n",
      "28868       0.000000           N         Y    0.499954       0.000000   \n",
      "17095       0.000000           N         Y    0.544632       0.000000   \n",
      "58562       0.023256           N         N    0.456199       0.000000   \n",
      "\n",
      "         avgmou  \n",
      "70087  0.150936  \n",
      "61324  0.075527  \n",
      "28868  0.053048  \n",
      "17095  0.298795  \n",
      "58562  0.107106  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "73062  0.407454   0.051282       WCMB     0.256974        N       EA   \n",
      "37501  0.200253   0.358974       WCMB     0.204320        N       AA   \n",
      "12109  0.496526   0.179487         WC     0.069948        N       AA   \n",
      "46000  0.456728   0.051282         WC     0.116242        N       EM   \n",
      "53722  0.576121   0.051282       WCMB     0.205476        N        A   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "73062  0.015866       0.016728       0.019719       0.022569  ...   \n",
      "37501  0.261830       0.246930       0.277588       0.317708  ...   \n",
      "12109  0.029915       0.026678       0.034509       0.039497  ...   \n",
      "46000  0.093311       0.134376       0.145999       0.167101  ...   \n",
      "53722  0.037324       0.021668       0.036405       0.041667  ...   \n",
      "\n",
      "       inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  callwait_Mean  refurb_new  \\\n",
      "73062       0.007701     0.000000         0.004114       0.000000           N   \n",
      "37501       0.173817     0.095956         0.170706       0.209302           N   \n",
      "12109       0.182618     0.161687         0.012487       0.000000           N   \n",
      "46000       0.011001     0.000000         0.000751       0.000000           N   \n",
      "53722       0.026403     0.000000         0.000000       0.000000           N   \n",
      "\n",
      "       dualband  change_mou  threeway_Mean    avgmou  churn  \n",
      "73062         N    0.481492       0.000000  0.049732    1.0  \n",
      "37501         Y    0.421767       0.000000  0.528230    1.0  \n",
      "12109         N    0.478076       0.068966  0.049592    1.0  \n",
      "46000         N    0.478169       0.000000  0.111510    1.0  \n",
      "53722         Y    0.472353       0.000000  0.054792    0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "73062  0.407454   0.051282       WCMB     0.256974        N       EA   \n",
      "37501  0.200253   0.358974       WCMB     0.204320        N       AA   \n",
      "12109  0.496526   0.179487         WC     0.069948        N       AA   \n",
      "46000  0.456728   0.051282         WC     0.116242        N       EM   \n",
      "53722  0.576121   0.051282       WCMB     0.205476        N        A   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "73062  0.015866       0.016728       0.019719       0.022569  ...   \n",
      "37501  0.261830       0.246930       0.277588       0.317708  ...   \n",
      "12109  0.029915       0.026678       0.034509       0.039497  ...   \n",
      "46000  0.093311       0.134376       0.145999       0.167101  ...   \n",
      "53722  0.037324       0.021668       0.036405       0.041667  ...   \n",
      "\n",
      "       custcare_Mean  inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  \\\n",
      "73062       0.000000       0.007701     0.000000         0.004114   \n",
      "37501       0.431193       0.173817     0.095956         0.170706   \n",
      "12109       0.165138       0.182618     0.161687         0.012487   \n",
      "46000       0.000000       0.011001     0.000000         0.000751   \n",
      "53722       0.000000       0.026403     0.000000         0.000000   \n",
      "\n",
      "       callwait_Mean  refurb_new  dualband  change_mou  threeway_Mean  \\\n",
      "73062       0.000000           N         N    0.481492       0.000000   \n",
      "37501       0.209302           N         Y    0.421767       0.000000   \n",
      "12109       0.000000           N         N    0.478076       0.068966   \n",
      "46000       0.000000           N         N    0.478169       0.000000   \n",
      "53722       0.000000           N         Y    0.472353       0.000000   \n",
      "\n",
      "         avgmou  \n",
      "73062  0.049732  \n",
      "37501  0.528230  \n",
      "12109  0.049592  \n",
      "46000  0.111510  \n",
      "53722  0.054792  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "14987  0.233102   0.358974       WCMB     0.205528        N       AA   \n",
      "73441  0.228048   0.358974       WCMB     0.205528        N       AA   \n",
      "15517  0.453569   0.051282       WCMB     0.218376        N       AA   \n",
      "41161  0.434618   0.128205       WCMB     0.154133        N       AA   \n",
      "55169  0.103601   0.179487       WCMB     0.256974        N        A   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "14987  0.119732       0.000000       0.000000       0.000000  ...   \n",
      "73441  0.037324       0.032924       0.043231       0.049479  ...   \n",
      "15517  0.015517       0.009284       0.017823       0.020399  ...   \n",
      "41161  0.020899       0.021717       0.035647       0.040799  ...   \n",
      "55169  0.226602       0.160715       0.269625       0.308594  ...   \n",
      "\n",
      "       inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  callwait_Mean  refurb_new  \\\n",
      "14987       0.000000          0.0         0.000000       0.000000           N   \n",
      "73441       0.016502          0.0         0.008342       0.011628           N   \n",
      "15517       0.004400          0.0         0.003117       0.011628           N   \n",
      "41161       0.000000          0.0         0.000000       0.000000           N   \n",
      "55169       0.194719          0.0         0.116293       0.220930           R   \n",
      "\n",
      "       dualband  change_mou  threeway_Mean    avgmou  churn  \n",
      "14987         Y    0.472445       0.000000  0.208831    1.0  \n",
      "73441         Y    0.455368       0.000000  0.087586    0.0  \n",
      "15517         N    0.453891       0.068966  0.031317    1.0  \n",
      "41161         Y    0.471891       0.000000  0.058244    1.0  \n",
      "55169         Y    0.368965       0.034483  0.203889    0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "        eqpdays  hnd_price hnd_webcap  totmrc_Mean asl_flag crclscod  \\\n",
      "14987  0.233102   0.358974       WCMB     0.205528        N       AA   \n",
      "73441  0.228048   0.358974       WCMB     0.205528        N       AA   \n",
      "15517  0.453569   0.051282       WCMB     0.218376        N       AA   \n",
      "41161  0.434618   0.128205       WCMB     0.154133        N       AA   \n",
      "55169  0.103601   0.179487       WCMB     0.256974        N        A   \n",
      "\n",
      "       mou_Mean  mou_cvce_Mean  complete_Mean  comp_vce_Mean  ...  \\\n",
      "14987  0.119732       0.000000       0.000000       0.000000  ...   \n",
      "73441  0.037324       0.032924       0.043231       0.049479  ...   \n",
      "15517  0.015517       0.009284       0.017823       0.020399  ...   \n",
      "41161  0.020899       0.021717       0.035647       0.040799  ...   \n",
      "55169  0.226602       0.160715       0.269625       0.308594  ...   \n",
      "\n",
      "       custcare_Mean  inonemin_Mean  cc_mou_Mean  mouiwylisv_Mean  \\\n",
      "14987            0.0       0.000000          0.0         0.000000   \n",
      "73441            0.0       0.016502          0.0         0.008342   \n",
      "15517            0.0       0.004400          0.0         0.003117   \n",
      "41161            0.0       0.000000          0.0         0.000000   \n",
      "55169            0.0       0.194719          0.0         0.116293   \n",
      "\n",
      "       callwait_Mean  refurb_new  dualband  change_mou  threeway_Mean  \\\n",
      "14987       0.000000           N         Y    0.472445       0.000000   \n",
      "73441       0.011628           N         Y    0.455368       0.000000   \n",
      "15517       0.011628           N         N    0.453891       0.068966   \n",
      "41161       0.000000           N         Y    0.471891       0.000000   \n",
      "55169       0.220930           R         Y    0.368965       0.034483   \n",
      "\n",
      "         avgmou  \n",
      "14987  0.208831  \n",
      "73441  0.087586  \n",
      "15517  0.031317  \n",
      "41161  0.058244  \n",
      "55169  0.203889  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1/100\n",
      "463/463 [==============================] - 35s 75ms/step - loss: 0.7941 - accuracy: 0.5158 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "463/463 [==============================] - 32s 70ms/step - loss: 0.6931 - accuracy: 0.5345 - val_loss: 0.6833 - val_accuracy: 0.5603\n",
      "Epoch 3/100\n",
      "463/463 [==============================] - 29s 64ms/step - loss: 0.6858 - accuracy: 0.5522 - val_loss: 0.6803 - val_accuracy: 0.5676\n",
      "Epoch 4/100\n",
      "463/463 [==============================] - 32s 68ms/step - loss: 0.6830 - accuracy: 0.5605 - val_loss: 0.6780 - val_accuracy: 0.5747\n",
      "Epoch 5/100\n",
      "463/463 [==============================] - 32s 68ms/step - loss: 0.6789 - accuracy: 0.5722 - val_loss: 0.6754 - val_accuracy: 0.5823\n",
      "Epoch 6/100\n",
      "463/463 [==============================] - 31s 66ms/step - loss: 0.6781 - accuracy: 0.5754 - val_loss: 0.6741 - val_accuracy: 0.5799\n",
      "Epoch 7/100\n",
      "463/463 [==============================] - 31s 67ms/step - loss: 0.6769 - accuracy: 0.5764 - val_loss: 0.6748 - val_accuracy: 0.5825\n",
      "Epoch 8/100\n",
      "463/463 [==============================] - 31s 67ms/step - loss: 0.6748 - accuracy: 0.5795 - val_loss: 0.6724 - val_accuracy: 0.5862\n",
      "Epoch 9/100\n",
      "463/463 [==============================] - 31s 68ms/step - loss: 0.6741 - accuracy: 0.5819 - val_loss: 0.6736 - val_accuracy: 0.5841\n",
      "Epoch 10/100\n",
      "463/463 [==============================] - 31s 66ms/step - loss: 0.6733 - accuracy: 0.5820 - val_loss: 0.6734 - val_accuracy: 0.5847\n",
      "Epoch 11/100\n",
      "463/463 [==============================] - 33s 71ms/step - loss: 0.6728 - accuracy: 0.5849 - val_loss: 0.6736 - val_accuracy: 0.5806\n",
      "Epoch 12/100\n",
      "463/463 [==============================] - 33s 71ms/step - loss: 0.6728 - accuracy: 0.5854 - val_loss: 0.6731 - val_accuracy: 0.5843\n",
      "Epoch 13/100\n",
      "463/463 [==============================] - 31s 67ms/step - loss: 0.6713 - accuracy: 0.5875 - val_loss: 0.6718 - val_accuracy: 0.5901\n",
      "Epoch 14/100\n",
      "463/463 [==============================] - 32s 69ms/step - loss: 0.6706 - accuracy: 0.5891 - val_loss: 0.6728 - val_accuracy: 0.5837\n",
      "Epoch 15/100\n",
      "463/463 [==============================] - 26s 57ms/step - loss: 0.6699 - accuracy: 0.5902 - val_loss: 0.6713 - val_accuracy: 0.5860\n",
      "Epoch 16/100\n",
      "463/463 [==============================] - 24s 51ms/step - loss: 0.6694 - accuracy: 0.5906 - val_loss: 0.6715 - val_accuracy: 0.5820\n",
      "Epoch 17/100\n",
      "463/463 [==============================] - 27s 59ms/step - loss: 0.6688 - accuracy: 0.5947 - val_loss: 0.6722 - val_accuracy: 0.5872\n",
      "Epoch 18/100\n",
      "463/463 [==============================] - 26s 56ms/step - loss: 0.6674 - accuracy: 0.5945 - val_loss: 0.6703 - val_accuracy: 0.5837\n",
      "Epoch 19/100\n",
      "463/463 [==============================] - 33s 70ms/step - loss: 0.6667 - accuracy: 0.5935 - val_loss: 0.6715 - val_accuracy: 0.5827\n",
      "Epoch 20/100\n",
      "463/463 [==============================] - 32s 69ms/step - loss: 0.6660 - accuracy: 0.5959 - val_loss: 0.6715 - val_accuracy: 0.5870\n",
      "Epoch 21/100\n",
      "463/463 [==============================] - 31s 66ms/step - loss: 0.6648 - accuracy: 0.5968 - val_loss: 0.6705 - val_accuracy: 0.5875\n",
      "Epoch 22/100\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 0.6643 - accuracy: 0.5984 - val_loss: 0.6697 - val_accuracy: 0.5870\n",
      "Epoch 23/100\n",
      "463/463 [==============================] - 29s 63ms/step - loss: 0.6633 - accuracy: 0.5979 - val_loss: 0.6716 - val_accuracy: 0.5831\n",
      "Epoch 24/100\n",
      "463/463 [==============================] - 28s 60ms/step - loss: 0.6633 - accuracy: 0.5996 - val_loss: 0.6712 - val_accuracy: 0.5858\n",
      "Epoch 25/100\n",
      "463/463 [==============================] - 32s 70ms/step - loss: 0.6615 - accuracy: 0.6030 - val_loss: 0.6705 - val_accuracy: 0.5840\n",
      "Epoch 26/100\n",
      "463/463 [==============================] - 34s 72ms/step - loss: 0.6606 - accuracy: 0.6020 - val_loss: 0.6720 - val_accuracy: 0.5856\n",
      "Epoch 27/100\n",
      "463/463 [==============================] - 32s 70ms/step - loss: 0.6608 - accuracy: 0.6010 - val_loss: 0.6698 - val_accuracy: 0.5854\n",
      "Epoch 28/100\n",
      "463/463 [==============================] - 29s 62ms/step - loss: 0.6584 - accuracy: 0.6027 - val_loss: 0.6709 - val_accuracy: 0.5862\n",
      "Epoch 29/100\n",
      "463/463 [==============================] - 30s 65ms/step - loss: 0.6579 - accuracy: 0.6054 - val_loss: 0.6691 - val_accuracy: 0.5872\n",
      "Epoch 30/100\n",
      "463/463 [==============================] - 31s 68ms/step - loss: 0.6570 - accuracy: 0.6058 - val_loss: 0.6713 - val_accuracy: 0.5869\n",
      "Epoch 31/100\n",
      "463/463 [==============================] - 30s 65ms/step - loss: 0.6555 - accuracy: 0.6089 - val_loss: 0.6703 - val_accuracy: 0.5880\n",
      "Epoch 32/100\n",
      "463/463 [==============================] - 29s 63ms/step - loss: 0.6554 - accuracy: 0.6083 - val_loss: 0.6694 - val_accuracy: 0.5883\n",
      "Epoch 33/100\n",
      "463/463 [==============================] - 31s 67ms/step - loss: 0.6531 - accuracy: 0.6122 - val_loss: 0.6703 - val_accuracy: 0.5881\n",
      "Epoch 34/100\n",
      "463/463 [==============================] - 28s 60ms/step - loss: 0.6524 - accuracy: 0.6170 - val_loss: 0.6684 - val_accuracy: 0.5914\n",
      "Epoch 35/100\n",
      "463/463 [==============================] - 28s 61ms/step - loss: 0.6518 - accuracy: 0.6136 - val_loss: 0.6704 - val_accuracy: 0.5926\n",
      "Epoch 36/100\n",
      "463/463 [==============================] - 30s 65ms/step - loss: 0.6516 - accuracy: 0.6151 - val_loss: 0.6708 - val_accuracy: 0.5921\n",
      "Epoch 37/100\n",
      "463/463 [==============================] - 28s 60ms/step - loss: 0.6496 - accuracy: 0.6175 - val_loss: 0.6692 - val_accuracy: 0.5890\n",
      "Epoch 38/100\n",
      "463/463 [==============================] - 33s 71ms/step - loss: 0.6490 - accuracy: 0.6182 - val_loss: 0.6695 - val_accuracy: 0.5900\n",
      "Epoch 39/100\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 0.6492 - accuracy: 0.6197 - val_loss: 0.6702 - val_accuracy: 0.5907\n",
      "Epoch 40/100\n",
      "463/463 [==============================] - 36s 79ms/step - loss: 0.6468 - accuracy: 0.6209 - val_loss: 0.6697 - val_accuracy: 0.5886\n",
      "Epoch 41/100\n",
      "463/463 [==============================] - 33s 71ms/step - loss: 0.6472 - accuracy: 0.6207 - val_loss: 0.6698 - val_accuracy: 0.5891\n",
      "Epoch 42/100\n",
      "463/463 [==============================] - 30s 65ms/step - loss: 0.6469 - accuracy: 0.6179 - val_loss: 0.6711 - val_accuracy: 0.5881\n",
      "Epoch 43/100\n",
      "463/463 [==============================] - 28s 60ms/step - loss: 0.6439 - accuracy: 0.6247 - val_loss: 0.6717 - val_accuracy: 0.5897\n",
      "Epoch 44/100\n",
      "463/463 [==============================] - 34s 74ms/step - loss: 0.6439 - accuracy: 0.6224 - val_loss: 0.6697 - val_accuracy: 0.5905\n",
      "Epoch 45/100\n",
      "463/463 [==============================] - 39s 84ms/step - loss: 0.6437 - accuracy: 0.6250 - val_loss: 0.6713 - val_accuracy: 0.5891\n",
      "Epoch 46/100\n",
      "463/463 [==============================] - 41s 87ms/step - loss: 0.6435 - accuracy: 0.6244 - val_loss: 0.6745 - val_accuracy: 0.5925\n",
      "Epoch 47/100\n",
      "463/463 [==============================] - 40s 86ms/step - loss: 0.6431 - accuracy: 0.6258 - val_loss: 0.6718 - val_accuracy: 0.5926\n",
      "Epoch 48/100\n",
      "463/463 [==============================] - 37s 81ms/step - loss: 0.6422 - accuracy: 0.6253 - val_loss: 0.6696 - val_accuracy: 0.5908\n",
      "Epoch 49/100\n",
      "463/463 [==============================] - 38s 81ms/step - loss: 0.6414 - accuracy: 0.6269 - val_loss: 0.6710 - val_accuracy: 0.5858\n",
      "Epoch 50/100\n",
      "463/463 [==============================] - 40s 87ms/step - loss: 0.6400 - accuracy: 0.6287 - val_loss: 0.6734 - val_accuracy: 0.5888\n",
      "Epoch 51/100\n",
      "463/463 [==============================] - 39s 84ms/step - loss: 0.6411 - accuracy: 0.6267 - val_loss: 0.6691 - val_accuracy: 0.5907\n",
      "Epoch 52/100\n",
      "463/463 [==============================] - 39s 84ms/step - loss: 0.6380 - accuracy: 0.6313 - val_loss: 0.6724 - val_accuracy: 0.5875\n",
      "Epoch 53/100\n",
      "463/463 [==============================] - 36s 77ms/step - loss: 0.6371 - accuracy: 0.6320 - val_loss: 0.6735 - val_accuracy: 0.5879\n",
      "Epoch 54/100\n",
      "463/463 [==============================] - 35s 75ms/step - loss: 0.6369 - accuracy: 0.6335 - val_loss: 0.6764 - val_accuracy: 0.5913\n",
      "Epoch 55/100\n",
      "463/463 [==============================] - 38s 82ms/step - loss: 0.6370 - accuracy: 0.6309 - val_loss: 0.6756 - val_accuracy: 0.5862\n",
      "Epoch 56/100\n",
      "463/463 [==============================] - 37s 79ms/step - loss: 0.6363 - accuracy: 0.6339 - val_loss: 0.6761 - val_accuracy: 0.5874\n",
      "Epoch 57/100\n",
      "463/463 [==============================] - 37s 79ms/step - loss: 0.6354 - accuracy: 0.6324 - val_loss: 0.6729 - val_accuracy: 0.5849\n",
      "Epoch 58/100\n",
      "463/463 [==============================] - 41s 88ms/step - loss: 0.6348 - accuracy: 0.6330 - val_loss: 0.6788 - val_accuracy: 0.5835\n",
      "Epoch 59/100\n",
      "463/463 [==============================] - 38s 81ms/step - loss: 0.6353 - accuracy: 0.6356 - val_loss: 0.6739 - val_accuracy: 0.5873\n",
      "Epoch 60/100\n",
      "463/463 [==============================] - 41s 90ms/step - loss: 0.6327 - accuracy: 0.6367 - val_loss: 0.6805 - val_accuracy: 0.5910\n",
      "Epoch 61/100\n",
      "463/463 [==============================] - 39s 84ms/step - loss: 0.6342 - accuracy: 0.6355 - val_loss: 0.6784 - val_accuracy: 0.5859\n",
      "Epoch 62/100\n",
      "463/463 [==============================] - 34s 74ms/step - loss: 0.6320 - accuracy: 0.6383 - val_loss: 0.6741 - val_accuracy: 0.5900\n",
      "Epoch 63/100\n",
      "463/463 [==============================] - 39s 85ms/step - loss: 0.6311 - accuracy: 0.6372 - val_loss: 0.6788 - val_accuracy: 0.5881\n",
      "Epoch 64/100\n",
      "463/463 [==============================] - 39s 84ms/step - loss: 0.6307 - accuracy: 0.6408 - val_loss: 0.6777 - val_accuracy: 0.5809\n",
      "Epoch 65/100\n",
      "463/463 [==============================] - 37s 79ms/step - loss: 0.6309 - accuracy: 0.6396 - val_loss: 0.6791 - val_accuracy: 0.5857\n",
      "Epoch 66/100\n",
      "463/463 [==============================] - 40s 86ms/step - loss: 0.6287 - accuracy: 0.6403 - val_loss: 0.6786 - val_accuracy: 0.5844\n",
      "Epoch 67/100\n",
      "463/463 [==============================] - 40s 85ms/step - loss: 0.6285 - accuracy: 0.6403 - val_loss: 0.6791 - val_accuracy: 0.5881\n",
      "Epoch 68/100\n",
      "463/463 [==============================] - 33s 72ms/step - loss: 0.6284 - accuracy: 0.6424 - val_loss: 0.6820 - val_accuracy: 0.5929\n",
      "Epoch 69/100\n",
      "463/463 [==============================] - 36s 79ms/step - loss: 0.6289 - accuracy: 0.6394 - val_loss: 0.6828 - val_accuracy: 0.5897\n",
      "Epoch 70/100\n",
      "175/463 [==========>...................] - ETA: 25s - loss: 0.6235 - accuracy: 0.6491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-196d62676198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m model.fit(train_ds,\n\u001b[0;32m     24\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m           epochs = 100)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.BatchNormalization(), \n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.BatchNormalization(), \n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.BatchNormalization(), \n",
    "  layers.Dropout(0.5),\n",
    "  #layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
    "  #layers.Dropout(0.3),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cal_back = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 3s 17ms/step - loss: 0.7618 - accuracy: 0.5816\n",
      "Accuracy 0.58162993\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest = pd.read_csv('test.csv')\n",
    "X_test = datatest.drop(['Customer_ID'], axis=1)\n",
    "#X_test = X_test.loc[:, most_important]\n",
    "\n",
    "\n",
    "for column in NUMERIC_COLUMNS:\n",
    "    X_test[column] = X_test[column].fillna(X_test[column].median())\n",
    "    X_test[column]=((X_test[column]-X_test[column].min())/(X_test[column].max()-X_test[column].min()))\n",
    "    \n",
    "for column in CATEGORICAL_COLUMNS:\n",
    "    X_test[column] = X_test[column].fillna(X_test[column].describe().top)\n",
    "\n",
    "testing = tf.data.Dataset.from_tensor_slices((dict(X_test))).batch(batch_size=200)\n",
    "preds = model.predict(testing)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(probs):\n",
    "    data_test = pd.read_csv('test.csv')\n",
    "    pd_result = pd.DataFrame({\"Customer_ID\": data_test.Customer_ID, \"churn\": probs})\n",
    "    pd_result.Customer_ID = pd_result.Customer_ID.astype(int)\n",
    "    pd_result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
